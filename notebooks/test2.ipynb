{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "from scipy.signal import lfilter\n",
    "\n",
    "class FeatureExtractor:\n",
    "    def __init__(self, n_mfcc=20):\n",
    "        self.n_mfcc = n_mfcc\n",
    "\n",
    "    def compute_mfccs(self, signal, sample_rate):\n",
    "        \"\"\"\n",
    "        Tính toán Mel-frequency cepstral coefficients (MFCCs) của tín hiệu âm thanh.\n",
    "        \"\"\"\n",
    "        mfccs = librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=self.n_mfcc)\n",
    "        return np.mean(mfccs.T, axis=0)\n",
    "\n",
    "    def compute_zcr(self, signal):\n",
    "        \"\"\"\n",
    "        Tính toán Zero Crossing Rate (ZCR) của tín hiệu âm thanh.\n",
    "        \"\"\"\n",
    "        zcr = librosa.feature.zero_crossing_rate(signal)[0]\n",
    "        zcr_mean = np.mean(zcr)\n",
    "        zcr_variance = np.var(zcr)\n",
    "        zcr_max = np.max(zcr)\n",
    "        zcr_min = np.min(zcr)\n",
    "        zcr_median = np.median(zcr)\n",
    "        return zcr_mean, zcr_variance, zcr_max, zcr_min, zcr_median\n",
    "\n",
    "    def extract_pitch(self, signal, sample_rate):\n",
    "        # Tính toán pitch sử dụng hàm estimate_tuning của Librosa\n",
    "        pitch, _ = librosa.core.piptrack(y=signal, sr=sample_rate)\n",
    "        \n",
    "        # Lấy giá trị pitch trung bình\n",
    "        mean_pitch = pitch.mean()\n",
    "        \n",
    "        return mean_pitch\n",
    "    \n",
    "    def extract_rms_features(self, y, frame_length=512, hop_length=256):\n",
    "        \"\"\"Trích xuất RMS energy và tính các giá trị thống kê.\"\"\"\n",
    "        rms = librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length)[0]\n",
    "        rms_mean = np.mean(rms)\n",
    "        rms_variance = np.var(rms)\n",
    "        rms_max = np.max(rms)\n",
    "        rms_min = np.min(rms)\n",
    "        rms_median = np.median(rms)\n",
    "        return rms_mean, rms_variance, rms_max, rms_min, rms_median\n",
    "    \n",
    "    import librosa\n",
    "\n",
    "    def calculate_formants(file_path):\n",
    "      # Load the audio file\n",
    "      signal, sr = librosa.load(file_path)\n",
    "\n",
    "      # Pre-emphasis\n",
    "      pre_emphasized_signal = np.append(signal[0], signal[1:] - 0.97 * signal[:-1])\n",
    "\n",
    "      # Compute the Linear Predictive Coding\n",
    "      lpc_order = 2 + sr // 1000\n",
    "      A = librosa.lpc(pre_emphasized_signal, order = lpc_order)\n",
    "      lpc_coeffs = lfilter([0] + -1*A[1:], [1], signal)\n",
    "\n",
    "      # Compute the roots of the LPC\n",
    "      rts = np.roots(A)\n",
    "      rts = [r for r in rts if np.imag(r) >= 0]\n",
    "\n",
    "      # Compute the angles and sort them by frequency\n",
    "      angz = np.arctan2(np.imag(rts), np.real(rts))\n",
    "      frqs = sorted(angz * (sr / (2 * np.pi)))\n",
    "\n",
    "      return frqs\n",
    "\n",
    "    def feature_engineering_for_file(self, audio_file):\n",
    "        \"\"\"\n",
    "        Trích xuất các đặc trưng MFCC, ZCR và Pitch từ một tệp âm thanh.\n",
    "        \"\"\"\n",
    "        signal, sample_rate = librosa.load(audio_file, sr=None)\n",
    "        if len(signal) >= 2048:\n",
    "            mfcc_array = self.compute_mfccs(signal, sample_rate)\n",
    "            zcr_mean, zcr_variance, zcr_max, zcr_min, zcr_median = self.compute_zcr(signal)\n",
    "            pitch = self.extract_pitch(signal, sample_rate)\n",
    "            rms_mean, rms_variance, rms_max, rms_min, rms_median = self.extract_rms_features(signal)\n",
    "            # hnr = self.calculate_hnr(signal)\n",
    "            return mfcc_array, zcr_mean, zcr_variance, zcr_max, zcr_min, zcr_median, pitch, rms_mean, rms_variance, rms_max, rms_min, rms_median\n",
    "        return None\n",
    "\n",
    "    def process_file(self, label, input_folder_path):\n",
    "        \"\"\"\n",
    "        Xử lý tất cả các tệp WAV trong thư mục để trích xuất các đặc trưng.\n",
    "        \"\"\"\n",
    "        # Tạo một DataFrame để lưu trữ đặc trưng MFCC\n",
    "        mfcc_data = pd.DataFrame()\n",
    "\n",
    "        for file_name in os.listdir(input_folder_path):\n",
    "            if file_name.endswith('.wav'):\n",
    "                file_path = os.path.join(input_folder_path, file_name)\n",
    "\n",
    "                features = self.feature_engineering_for_file(file_path)\n",
    "                if features is not None:\n",
    "                    mfcc_array, zcr_mean, zcr_variance, zcr_max, zcr_min, zcr_median, pitch, rms_mean, rms_variance, rms_max, rms_min, rms_median = features\n",
    "                    \n",
    "                    mfcc_df = pd.DataFrame(mfcc_array.reshape(1, -1), columns=[f'mfcc_{i+1}' for i in range(len(mfcc_array))])\n",
    "\n",
    "                    mfcc_df['label'] = label\n",
    "                    mfcc_df['file'] = file_name\n",
    "                    mfcc_df['zcr_mean'] = zcr_mean\n",
    "                    mfcc_df['zcr_variance'] = zcr_variance\n",
    "                    mfcc_df['zcr_max'] = zcr_max\n",
    "                    mfcc_df['zcr_min'] = zcr_min\n",
    "                    mfcc_df['zcr_median'] = zcr_median\n",
    "                    mfcc_df['Pitch'] = pitch\n",
    "                    mfcc_df['rms_mean'] = rms_mean\n",
    "                    mfcc_df['rms_variance'] = rms_variance\n",
    "                    mfcc_df['rms_max'] = rms_max\n",
    "                    mfcc_df['rms_min'] = rms_min\n",
    "                    mfcc_df['rms_median'] = rms_median\n",
    "                    # mfcc_df['hnr'] = hnr\n",
    "                    \n",
    "                    mfcc_data = pd.concat([mfcc_data, mfcc_df], ignore_index=True)\n",
    "            \n",
    "        return mfcc_data\n",
    "\n",
    "    def process_folder(self, input_folder, output_csv_path):\n",
    "        \"\"\"\n",
    "        Xử lý tất cả các thư mục con trong thư mục đầu vào để trích xuất các đặc trưng và lưu chúng vào một tệp CSV.\n",
    "        \"\"\"\n",
    "        # Tạo một DataFrame để lưu trữ dữ liệu MFCC\n",
    "        mfcc_data = pd.DataFrame()\n",
    "\n",
    "        # Duyệt qua tất cả các thư mục con trong thư mục đầu vào\n",
    "        for root, dirs, files in os.walk(input_folder):\n",
    "            for folder in dirs:\n",
    "                # Xác định đường dẫn của thư mục con trong thư mục đầu vào\n",
    "                subdirectory_input = os.path.join(root, folder)\n",
    "                # Xử lý các tệp trong thư mục con và thêm dữ liệu MFCC vào DataFrame\n",
    "                mfcc_df = self.process_file(folder, subdirectory_input)\n",
    "                mfcc_data = pd.concat([mfcc_data, mfcc_df], ignore_index=True)\n",
    "\n",
    "        # Lưu dữ liệu MFCC vào tệp CSV\n",
    "        mfcc_data.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureExtractor = FeatureExtractor(20)\n",
    "featureExtractor.process_folder('D:/data_analysis/speech_emotion_recognition/data/EnglishDataset/cleaned_data','feature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017103037 0.026597798\n",
      "HNR: -1.91772451070778 dB\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def calculate_hnr(file_path):\n",
    "    # Tải tín hiệu âm thanh\n",
    "    signal, sample_rate = librosa.load(file_path, sr=None)\n",
    "    \n",
    "    # Phân tách tín hiệu thành hài hòa và nhiễu\n",
    "    harmonic, percussive = librosa.effects.hpss(signal)\n",
    "    \n",
    "    # Tính tổng năng lượng của hài hòa và nhiễu\n",
    "    harmonic_energy = np.sum(harmonic ** 2)\n",
    "    percussive_energy = np.sum(percussive ** 2)\n",
    "\n",
    "    print(harmonic_energy, percussive_energy)\n",
    "    \n",
    "    # Tính HNR\n",
    "    hnr = 10 * np.log10(harmonic_energy / (percussive_energy + 0.0000000001))  # Thêm 1e-6 để tránh chia cho 0\n",
    "    \n",
    "    return hnr\n",
    "\n",
    "# Sử dụng chức năng\n",
    "file_path = r'D:\\data_analysis\\speech_emotion_recognition\\data\\EnglishDataset\\cleaned_data\\Sad\\03-01-04-01-01-01-09.wav'\n",
    "hnr_value = calculate_hnr(file_path)\n",
    "print(f\"HNR: {hnr_value} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 474.75648544 3076.32386616 1868.76391544 ...  683.06070027  261.61080038\n",
      "    0.        ]\n",
      "11617.923743259638\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m signal, sample_rate \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(audio_file, sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     49\u001b[0m formants \u001b[38;5;241m=\u001b[39m extract_formants(signal, sample_rate)\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFormant F1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mformants\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Hz, Formant F2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mformants[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Hz, Formant F3: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mformants[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Hz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def extract_formants(signal, sample_rate, order=None):\n",
    "    if order is None:\n",
    "        order = 2 + sample_rate // 1000  # Số lượng hệ số LPC\n",
    "\n",
    "    window_length = int(0.025 * sample_rate)  # Độ dài cửa sổ là 25ms\n",
    "    hop_length = int(0.01 * sample_rate)  # Bước nhảy là 10ms\n",
    "\n",
    "    frames = librosa.util.frame(signal, frame_length=window_length, hop_length=hop_length)\n",
    "\n",
    "    formant_freqs = []\n",
    "\n",
    "    for frame in frames.T:\n",
    "        frame = frame * np.hamming(len(frame))\n",
    "        \n",
    "        # Tính hệ số LPC\n",
    "        try:\n",
    "            lpc_coeffs = librosa.lpc(frame, order=order)\n",
    "        except np.linalg.LinAlgError:\n",
    "            continue  # Bỏ qua các khung không thể tính LPC\n",
    "\n",
    "        roots = np.roots(lpc_coeffs)\n",
    "        roots = roots[np.imag(roots) >= 0]\n",
    "\n",
    "        angz = np.arctan2(np.imag(roots), np.real(roots))\n",
    "\n",
    "        formant_freqs_frame = angz * (sample_rate / (2 * np.pi))\n",
    "        formant_freqs.append(formant_freqs_frame)\n",
    "\n",
    "    if len(formant_freqs) == 0:\n",
    "        raise ValueError(\"Không có formant nào được trích xuất.\")\n",
    "\n",
    "    formant_freqs = np.concatenate(formant_freqs)\n",
    "    mean_formant_freqs = np.mean(formant_freqs, axis=0)\n",
    "\n",
    "    print(formant_freqs)\n",
    "    print(mean_formant_freqs)\n",
    "\n",
    "    # if len(mean_formant_freqs) < 3:\n",
    "    #     raise ValueError(\"Không có đủ các formant để tính toán.\")\n",
    "\n",
    "    # return mean_formant_freqs[:3]\n",
    "\n",
    "# Ví dụ sử dụng hàm trên một tệp âm thanh\n",
    "audio_file = r'D:\\data_analysis\\speech_emotion_recognition\\data\\EnglishDataset\\cleaned_data\\Angry\\03-01-05-01-01-01-03.wav'\n",
    "signal, sample_rate = librosa.load(audio_file, sr=None)\n",
    "formants = extract_formants(signal, sample_rate)\n",
    "print(f\"Formant F1: {formants[0]} Hz, Formant F2: {formants[1]} Hz, Formant F3: {formants[2]} Hz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "lpc() missing 1 required keyword-only argument: 'order'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m audio_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata_analysis\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mspeech_emotion_recognition\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mEnglishDataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcleaned_data\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAngry\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m03-01-05-01-01-01-03.wav\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m signal, sample_rate \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(audio_file, sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m----> 4\u001b[0m formants \u001b[38;5;241m=\u001b[39m \u001b[43mextract_formants\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFormant F1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mformants[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Hz, Formant F2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mformants[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Hz, Formant F3: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mformants[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Hz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 21\u001b[0m, in \u001b[0;36mextract_formants\u001b[1;34m(signal, sample_rate)\u001b[0m\n\u001b[0;32m     18\u001b[0m frame \u001b[38;5;241m=\u001b[39m frame \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mhamming(\u001b[38;5;28mlen\u001b[39m(frame))\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Tính hệ số LPC\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m lpc_coeffs \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlpc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Tính toán tần số formant từ hệ số LPC\u001b[39;00m\n\u001b[0;32m     24\u001b[0m roots \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mroots(lpc_coeffs)\n",
      "\u001b[1;31mTypeError\u001b[0m: lpc() missing 1 required keyword-only argument: 'order'"
     ]
    }
   ],
   "source": [
    "# Ví dụ sử dụng hàm trên một tệp âm thanh\n",
    "audio_file = r'D:\\data_analysis\\speech_emotion_recognition\\data\\EnglishDataset\\cleaned_data\\Angry\\03-01-05-01-01-01-03.wav'\n",
    "signal, sample_rate = librosa.load(audio_file, sr=None)\n",
    "formants = extract_formants(signal, sample_rate)\n",
    "print(f\"Formant F1: {formants[0]} Hz, Formant F2: {formants[1]} Hz, Formant F3: {formants[2]} Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formants: [721.3824, 1401.1196, 2236.8738, 3239.1687, 4117.2256, 5096.966, 5802.739, 6933.5645, 8002.1777, 8683.482, 9260.525, 10236.741]\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from scipy.signal import lfilter\n",
    "\n",
    "def calculate_formants(file_path):\n",
    "    # Load the audio file\n",
    "    signal, sr = librosa.load(file_path)\n",
    "\n",
    "    # Pre-emphasis\n",
    "    pre_emphasized_signal = np.append(signal[0], signal[1:] - 0.97 * signal[:-1])\n",
    "\n",
    "    # Compute the Linear Predictive Coding\n",
    "    lpc_order = 2 + sr // 1000\n",
    "    A = librosa.lpc(pre_emphasized_signal, order = lpc_order)\n",
    "    lpc_coeffs = lfilter([0] + -1*A[1:], [1], signal)\n",
    "\n",
    "    # Compute the roots of the LPC\n",
    "    rts = np.roots(A)\n",
    "    rts = [r for r in rts if np.imag(r) >= 0]\n",
    "\n",
    "    # Compute the angles and sort them by frequency\n",
    "    angz = np.arctan2(np.imag(rts), np.real(rts))\n",
    "    frqs = sorted(angz * (sr / (2 * np.pi)))\n",
    "\n",
    "    return frqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formants: [721.3824, 1401.1196, 2236.8738, 3239.1687, 4117.2256, 5096.966, 5802.739, 6933.5645, 8002.1777, 8683.482, 9260.525, 10236.741]\n",
      "Formants: [679.07135, 1534.5476, 2292.1736, 3679.732, 4234.2246, 4325.078, 5888.1074, 6072.527, 7461.582, 8586.377, 9380.355, 10195.942]\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "formants = calculate_formants(r'D:\\data_analysis\\speech_emotion_recognition\\data\\EnglishDataset\\cleaned_data\\Angry\\03-01-05-01-01-01-03.wav')\n",
    "print('Formants:', formants)\n",
    "\n",
    "formants = calculate_formants(r'D:\\data_analysis\\speech_emotion_recognition\\data\\EnglishDataset\\cleaned_data\\Happy\\03-01-03-01-01-01-07.wav')\n",
    "print('Formants:', formants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formants: [688.7086, 1428.6176, 2540.258, 3246.2712, 4149.397, 4606.274, 6000.5366, 6922.5654, 7912.6494, 8821.534, 9426.873, 10173.98]\n"
     ]
    }
   ],
   "source": [
    "formants = calculate_formants(r'D:\\data_analysis\\speech_emotion_recognition\\data\\EnglishDataset\\cleaned_data\\Angry\\YAF_witch_angry.wav')\n",
    "print('Formants:', formants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formants: [719.67535, 1441.8665, 1773.3247, 2716.288, 3936.2014, 5126.2817, 5596.3994, 6555.4165, 7550.396, 8533.014, 9380.397, 10208.539]\n"
     ]
    }
   ],
   "source": [
    "formants = calculate_formants(r'D:\\data_analysis\\speech_emotion_recognition\\data\\EnglishDataset\\cleaned_data\\Sad\\03-01-04-01-01-01-12.wav')\n",
    "print('Formants:', formants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formants: [516.06903, 1151.0686, 1947.4172, 2504.1653, 3575.7183, 4360.3867, 4878.4766, 5666.582, 6314.458, 6847.5005, 7261.4365, 7563.0835]\n"
     ]
    }
   ],
   "source": [
    "formants = calculate_formants(r'D:\\data_analysis\\speech_emotion_recognition\\data\\EnglishDataset\\cleaned_data\\Sad\\1005_MTI_SAD_XX.wav')\n",
    "print('Formants:', formants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "class FeatureExtractor:\n",
    "    def __init__(self, n_mfcc=20):\n",
    "        self.n_mfcc = n_mfcc\n",
    "\n",
    "    def compute_mfccs(self, signal, sample_rate):\n",
    "        \"\"\"\n",
    "        Tính toán Mel-frequency cepstral coefficients (MFCCs) của tín hiệu âm thanh.\n",
    "        \"\"\"\n",
    "        mfccs = librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=self.n_mfcc)\n",
    "        return np.mean(mfccs.T, axis=0)\n",
    "\n",
    "    def compute_zcr(self, signal):\n",
    "        \"\"\"\n",
    "        Tính toán Zero Crossing Rate (ZCR) của tín hiệu âm thanh.\n",
    "        \"\"\"\n",
    "        zcr = librosa.feature.zero_crossing_rate(signal)[0]\n",
    "        zcr_mean = np.mean(zcr)\n",
    "        zcr_variance = np.var(zcr)\n",
    "        zcr_max = np.max(zcr)\n",
    "        zcr_min = np.min(zcr)\n",
    "        zcr_median = np.median(zcr)\n",
    "        return zcr_mean, zcr_variance, zcr_max, zcr_min, zcr_median\n",
    "\n",
    "    def extract_pitch(self, signal, sample_rate):\n",
    "        # Tính toán pitch sử dụng hàm estimate_tuning của Librosa\n",
    "        pitch, _ = librosa.core.piptrack(y=signal, sr=sample_rate)\n",
    "        \n",
    "        # Lấy giá trị pitch trung bình\n",
    "        mean_pitch = pitch.mean()\n",
    "        \n",
    "        return mean_pitch\n",
    "    \n",
    "    def extract_rms_features(self, y, frame_length=512, hop_length=256):\n",
    "        \"\"\"Trích xuất RMS energy và tính các giá trị thống kê.\"\"\"\n",
    "        rms = librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length)[0]\n",
    "        rms_mean = np.mean(rms)\n",
    "        rms_variance = np.var(rms)\n",
    "        rms_max = np.max(rms)\n",
    "        rms_min = np.min(rms)\n",
    "        rms_median = np.median(rms)\n",
    "        return rms_mean, rms_variance, rms_max, rms_min, rms_median\n",
    "\n",
    "    def calculate_formants(self, signal, sr):\n",
    "        # Pre-emphasis\n",
    "        pre_emphasized_signal = np.append(signal[0], signal[1:] - 0.97 * signal[:-1])\n",
    "\n",
    "        # Compute the Linear Predictive Coding\n",
    "        lpc_order = 2 + sr // 1000\n",
    "        A = librosa.lpc(pre_emphasized_signal, order = lpc_order)\n",
    "\n",
    "        # Compute the roots of the LPC\n",
    "        rts = np.roots(A)\n",
    "        rts = [r for r in rts if np.imag(r) >= 0]\n",
    "\n",
    "        # Compute the angles and sort them by frequency\n",
    "        angz = np.arctan2(np.imag(rts), np.real(rts))\n",
    "        frqs = sorted(angz * (sr / (2 * np.pi)))\n",
    "\n",
    "        mean_formant = np.mean(frqs)\n",
    "        variance_formant = np.var(frqs)\n",
    "        max_formant = np.max(frqs)\n",
    "        min_formant = np.min(frqs)\n",
    "        median_formant = np.median(frqs)\n",
    "        return mean_formant, variance_formant, max_formant, min_formant, median_formant\n",
    "\n",
    "    def feature_engineering_for_file(self, audio_file):\n",
    "        \"\"\"\n",
    "        Trích xuất các đặc trưng MFCC, ZCR và Pitch từ một tệp âm thanh.\n",
    "        \"\"\"\n",
    "        signal, sample_rate = librosa.load(audio_file, sr=None)\n",
    "        if len(signal) >= 2048:\n",
    "            mfcc_array = self.compute_mfccs(signal, sample_rate)\n",
    "            zcr_mean, zcr_variance, zcr_max, zcr_min, zcr_median = self.compute_zcr(signal)\n",
    "            pitch = self.extract_pitch(signal, sample_rate)\n",
    "            rms_mean, rms_variance, rms_max, rms_min, rms_median = self.extract_rms_features(signal)\n",
    "            mean_formant, variance_formant, max_formant, min_formant, median_formant = self.calculate_formants(signal, sample_rate)\n",
    "            return mfcc_array, zcr_mean, zcr_variance, zcr_max, zcr_min, zcr_median, pitch, rms_mean, rms_variance, rms_max, rms_min, rms_median, mean_formant, variance_formant, max_formant, min_formant, median_formant\n",
    "        return None\n",
    "\n",
    "    def process_file(self, label, input_folder_path):\n",
    "        \"\"\"\n",
    "        Xử lý tất cả các tệp WAV trong thư mục để trích xuất các đặc trưng.\n",
    "        \"\"\"\n",
    "        # Tạo một DataFrame để lưu trữ đặc trưng MFCC\n",
    "        mfcc_data = pd.DataFrame()\n",
    "\n",
    "        for file_name in os.listdir(input_folder_path):\n",
    "            if file_name.endswith('.wav'):\n",
    "                file_path = os.path.join(input_folder_path, file_name)\n",
    "\n",
    "                features = self.feature_engineering_for_file(file_path)\n",
    "                if features is not None:\n",
    "                    mfcc_array, zcr_mean, zcr_variance, zcr_max, zcr_min, zcr_median, pitch, rms_mean, rms_variance, rms_max, rms_min, rms_median, mean_formant, variance_formant, max_formant, min_formant, median_formant = features\n",
    "                    mfcc_df = pd.DataFrame(mfcc_array.reshape(1, -1), columns=[f'mfcc_{i+1}' for i in range(len(mfcc_array))])\n",
    "\n",
    "                    mfcc_df['label'] = label\n",
    "                    mfcc_df['file'] = file_name\n",
    "                    mfcc_df['zcr_mean'] = zcr_mean\n",
    "                    mfcc_df['zcr_variance'] = zcr_variance\n",
    "                    mfcc_df['zcr_max'] = zcr_max\n",
    "                    mfcc_df['zcr_min'] = zcr_min\n",
    "                    mfcc_df['zcr_median'] = zcr_median\n",
    "                    mfcc_df['Pitch'] = pitch\n",
    "                    mfcc_df['rms_mean'] = rms_mean\n",
    "                    mfcc_df['rms_variance'] = rms_variance\n",
    "                    mfcc_df['rms_max'] = rms_max\n",
    "                    mfcc_df['rms_min'] = rms_min\n",
    "                    mfcc_df['rms_median'] = rms_median\n",
    "                    #mean_formant, variance_formant, max_formant, min_formant, median_formant\n",
    "                    mfcc_df['mean_formant'] = mean_formant\n",
    "                    mfcc_df['variance_formant'] = variance_formant\n",
    "                    mfcc_df['max_formant'] = max_formant\n",
    "                    mfcc_df['min_formant'] = min_formant\n",
    "                    mfcc_df['median_formant'] = median_formant\n",
    "                    mfcc_data = pd.concat([mfcc_data, mfcc_df], ignore_index=True)\n",
    "            \n",
    "        return mfcc_data\n",
    "\n",
    "    def process_folder(self, input_folder, output_csv_path):\n",
    "        \"\"\"\n",
    "        Xử lý tất cả các thư mục con trong thư mục đầu vào để trích xuất các đặc trưng và lưu chúng vào một tệp CSV.\n",
    "        \"\"\"\n",
    "        # Tạo một DataFrame để lưu trữ dữ liệu MFCC\n",
    "        mfcc_data = pd.DataFrame()\n",
    "\n",
    "        # Duyệt qua tất cả các thư mục con trong thư mục đầu vào\n",
    "        for root, dirs, files in os.walk(input_folder):\n",
    "            for folder in dirs:\n",
    "                # Xác định đường dẫn của thư mục con trong thư mục đầu vào\n",
    "                subdirectory_input = os.path.join(root, folder)\n",
    "                # Xử lý các tệp trong thư mục con và thêm dữ liệu MFCC vào DataFrame\n",
    "                mfcc_df = self.process_file(folder, subdirectory_input)\n",
    "                mfcc_data = pd.concat([mfcc_data, mfcc_df], ignore_index=True)\n",
    "\n",
    "        # Lưu dữ liệu MFCC vào tệp CSV\n",
    "        mfcc_data.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureExtractor = FeatureExtractor(40)\n",
    "featureExtractor.process_folder('D:/data_analysis/speech_emotion_recognition/data/EnglishDataset/cleaned_data','feature.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
