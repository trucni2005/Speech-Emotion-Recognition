{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\data_analysis\\\\speech_emotion_recognition\\\\audio_test\\\\Bong_Dung_Muon_Khoc\\\\divide_segment\\\\1\\\\segment_321.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 60\u001b[0m\n\u001b[0;32m     57\u001b[0m     plot_audio(audio_data, sample_rate, filtered_audio_data)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 43\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# Đọc file âm thanh\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata_analysis\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mspeech_emotion_recognition\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124maudio_test\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mBong_Dung_Muon_Khoc\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdivide_segment\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msegment_321.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 43\u001b[0m     sample_rate, audio_data \u001b[38;5;241m=\u001b[39m \u001b[43mread_audio_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m# Áp dụng bộ lọc thông thấp cho dữ liệu âm thanh\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     cutoff_freq_low \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m700\u001b[39m  \u001b[38;5;66;03m# Tần số cắt cho bộ lọc thông thấp\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m, in \u001b[0;36mread_audio_file\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_audio_file\u001b[39m(file_path):\n\u001b[0;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Đọc file âm thanh và trả về tỷ lệ mẫu và dữ liệu âm thanh đã chuẩn hóa.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     sample_rate, audio_data \u001b[38;5;241m=\u001b[39m \u001b[43mwavfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     audio_data \u001b[38;5;241m=\u001b[39m audio_data \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(np\u001b[38;5;241m.\u001b[39mabs(audio_data))  \u001b[38;5;66;03m# Chuẩn hóa dữ liệu âm thanh về phạm vi từ -1 đến 1\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sample_rate, audio_data\n",
      "File \u001b[1;32md:\\data_analysis\\speech_emotion_recognition\\.venv\\Lib\\site-packages\\scipy\\io\\wavfile.py:647\u001b[0m, in \u001b[0;36mread\u001b[1;34m(filename, mmap)\u001b[0m\n\u001b[0;32m    645\u001b[0m     mmap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 647\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     file_size, is_big_endian \u001b[38;5;241m=\u001b[39m _read_riff_chunk(fid)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\data_analysis\\\\speech_emotion_recognition\\\\audio_test\\\\Bong_Dung_Muon_Khoc\\\\divide_segment\\\\1\\\\segment_321.wav'"
     ]
    }
   ],
   "source": [
    "from scipy.io import wavfile\n",
    "from scipy.signal import butter, filtfilt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_audio_file(file_path):\n",
    "    \"\"\"Đọc file âm thanh và trả về tỷ lệ mẫu và dữ liệu âm thanh đã chuẩn hóa.\"\"\"\n",
    "    sample_rate, audio_data = wavfile.read(file_path)\n",
    "    audio_data = audio_data / np.max(np.abs(audio_data))  # Chuẩn hóa dữ liệu âm thanh về phạm vi từ -1 đến 1\n",
    "    return sample_rate, audio_data\n",
    "\n",
    "def apply_lowpass_filter(audio_data, sample_rate, cutoff_freq, order):\n",
    "    \"\"\"Áp dụng bộ lọc thông thấp cho dữ liệu âm thanh.\"\"\"\n",
    "    b, a = butter(order, cutoff_freq / (sample_rate / 2), btype='low', analog=False)\n",
    "    filtered_audio_data = filtfilt(b, a, audio_data)\n",
    "    return filtered_audio_data\n",
    "\n",
    "def apply_highpass_filter(audio_data, sample_rate, cutoff_freq, order):\n",
    "    \"\"\"Áp dụng bộ lọc thông cao cho dữ liệu âm thanh.\"\"\"\n",
    "    b, a = butter(order, cutoff_freq / (sample_rate / 2), btype='high', analog=False)\n",
    "    filtered_audio_data = filtfilt(b, a, audio_data)\n",
    "    return filtered_audio_data\n",
    "\n",
    "def save_audio_file(output_file, sample_rate, audio_data):\n",
    "    \"\"\"Lưu dữ liệu âm thanh vào file mới.\"\"\"\n",
    "    wavfile.write(output_file, sample_rate, np.array(audio_data * (2**15 - 1), dtype=np.int16))\n",
    "\n",
    "def plot_audio(audio_data, sample_rate, filtered_audio_data):\n",
    "    \"\"\"Hiển thị âm thanh gốc và âm thanh đã lọc.\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(np.arange(len(audio_data)) / sample_rate, audio_data, label='Original Audio')\n",
    "    plt.plot(np.arange(len(filtered_audio_data)) / sample_rate, filtered_audio_data, label='Filtered Audio (Thresholded)')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.title('Original vs. Filtered Audio')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    # Đọc file âm thanh\n",
    "    file_path = r\"D:\\data_analysis\\speech_emotion_recognition\\audio_test\\Bong_Dung_Muon_Khoc\\divide_segment\\1\\segment_321.wav\"\n",
    "    sample_rate, audio_data = read_audio_file(file_path)\n",
    "\n",
    "    # Áp dụng bộ lọc thông thấp cho dữ liệu âm thanh\n",
    "    cutoff_freq_low = 700  # Tần số cắt cho bộ lọc thông thấp\n",
    "    cutoff_freq_high = 200\n",
    "    order = 5  # Bậc của bộ lọc\n",
    "    filtered_audio_data = apply_lowpass_filter(audio_data, sample_rate, cutoff_freq_low, order)\n",
    "    filtered_audio_data = apply_highpass_filter(audio_data, sample_rate, cutoff_freq_high, order)\n",
    "\n",
    "    # Lưu dữ liệu âm thanh đã lọc vào file mới\n",
    "    output_file = 'filtered_audio_thresholded.wav'\n",
    "    save_audio_file(output_file, sample_rate, filtered_audio_data)\n",
    "\n",
    "    # Hiển thị âm thanh gốc và âm thanh đã lọc\n",
    "    plot_audio(audio_data, sample_rate, filtered_audio_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\data_analysis\\speech_emotion_recognition\\.venv\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "\n",
    "def normalize_audio(input_file, output_file, target_dBFS):\n",
    "    # Tải tệp âm thanh vào dưới dạng mảng numpy và mức âm lượng hiện tại\n",
    "    audio, sr = librosa.load(input_file, sr=None)\n",
    "    current_dBFS = librosa.amplitude_to_db(np.max(np.abs(audio)), ref=1.0)\n",
    "\n",
    "    # Tính toán độ chênh lệch giữa mức âm thanh hiện tại và mức âm thanh mục tiêu\n",
    "    dBFS_change = target_dBFS - current_dBFS\n",
    "\n",
    "    # Chuẩn hóa âm thanh bằng cách thay đổi biên độ\n",
    "    normalized_audio = audio * (10.0 ** (dBFS_change / 20.0))\n",
    "\n",
    "    # Ghi âm thanh đã được chuẩn hóa vào tệp output\n",
    "    librosa.output.write_wav(output_file, normalized_audio, sr)\n",
    "\n",
    "# Sử dụng hàm normalize_audio để chuẩn hóa mức âm thanh của các tệp âm thanh\n",
    "input_file = \"input_audio.wav\"\n",
    "output_file = \"normalized_audio.wav\"\n",
    "target_dBFS = -20  # Mức âm thanh mục tiêu\n",
    "normalize_audio(input_file, output_file, target_dBFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "def normalize_audio(input_file, output_file, target_dBFS):\n",
    "    # Tải tệp âm thanh vào dưới dạng mảng numpy và mức âm lượng hiện tại\n",
    "    audio, sr = librosa.load(input_file, sr=None)\n",
    "    current_dBFS = librosa.amplitude_to_db(np.max(np.abs(audio)), ref=1.0)\n",
    "\n",
    "    # Tính toán độ chênh lệch giữa mức âm thanh hiện tại và mức âm thanh mục tiêu\n",
    "    dBFS_change = target_dBFS - current_dBFS\n",
    "\n",
    "    # Chuẩn hóa âm thanh bằng cách thay đổi biên độ\n",
    "    normalized_audio = audio * (10.0 ** (dBFS_change / 20.0))\n",
    "\n",
    "    # Ghi âm thanh đã được chuẩn hóa vào tệp output\n",
    "    sf.write(output_file, normalized_audio, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sử dụng hàm normalize_audio để chuẩn hóa mức âm thanh của các tệp âm thanh\n",
    "input_file = r\"D:\\data_analysis\\speech_emotion_recognition\\audio_test/Bong_Dung_Muon_Khoc/divide_segment/1/Sad/segment_69.wav\"\n",
    "output_file = \"segment_69.wav\"\n",
    "target_dBFS = -20  # Mức âm thanh mục tiêu\n",
    "normalize_audio(input_file, output_file, target_dBFS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
