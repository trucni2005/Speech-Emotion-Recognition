{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from loguru import logger\n",
    "\n",
    "class FineTuningModelUsingMelSpectrogram:\n",
    "    \"\"\"\n",
    "    Mô hình nhận dạng cảm xúc trong giọng nói sử dụng CNN.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_path, train_image_path, test_image_path, val_image_path, learning_rate=0.0001):\n",
    "        \"\"\"\n",
    "        Khởi tạo các thuộc tính cần thiết cho đối tượng FineTuningModelUsingMelSpectrogram.\n",
    "        \"\"\"\n",
    "        self.model = self.load_model(model_path)\n",
    "\n",
    "    def read_and_process_image(self, image_path, target_size=(128, 128)):\n",
    "        \"\"\"\n",
    "        Đọc và xử lý hình ảnh từ đường dẫn cho trước.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            if img is None:\n",
    "                logger.error(f\"Không thể đọc hình ảnh từ đường dẫn: {image_path}\")\n",
    "                return None\n",
    "            img = cv2.resize(img, target_size)\n",
    "            img = img.astype('float32') / 255.0\n",
    "            return img\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Lỗi khi đọc và xử lý hình ảnh từ đường dẫn: {image_path}, Lỗi: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def process_data(self, csv_file):\n",
    "        \"\"\"\n",
    "        Xử lý dữ liệu từ file CSV chứa đường dẫn hình ảnh và nhãn.\n",
    "        \"\"\"\n",
    "        encoder = OneHotEncoder()\n",
    "        df = pd.read_csv(csv_file)\n",
    "        X = []\n",
    "        y = df['label']\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            image_path = row['file_path']\n",
    "            img = self.read_and_process_image(image_path)\n",
    "            if img is not None:\n",
    "                X.append(img)\n",
    "        \n",
    "        X_tensor = np.array(X)\n",
    "        y = encoder.fit_transform(np.array(y).reshape(-1, 1)).toarray()\n",
    "        return X_tensor, y\n",
    "    \n",
    "    def compile_model(self):\n",
    "        \"\"\"\n",
    "        Thiết lập và biên dịch mô hình CNN.\n",
    "        \"\"\"\n",
    "        optimizer = Adam(learning_rate=self.learning_rate)\n",
    "        self.model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    def load_model(self, model_path):\n",
    "        \"\"\"\n",
    "        Tải mô hình đã huấn luyện từ file.\n",
    "        \"\"\"\n",
    "        self.model = load_model(model_path)\n",
    "        self.compile_model()\n",
    "    \n",
    "    def fine_tune(self, X_train, y_train, X_val, y_val, model_path, n_mels, epochs=50, batch_size=64):\n",
    "        \"\"\"\n",
    "        Fine-tune mô hình với dữ liệu mới.\n",
    "        \"\"\"\n",
    "        self.load_model(model_path)\n",
    "        \n",
    "        cnn_model_checkpoint = ModelCheckpoint(f'fine_tuned_cnn_model_weights_using_mel_spectrogram_{n_mels}.h5', monitor='val_accuracy', save_best_only=True)\n",
    "        early_stop = EarlyStopping(monitor='val_loss', mode='min', patience=8, restore_best_weights=True)\n",
    "        lr_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "        \n",
    "        history = self.model.fit(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val), batch_size=batch_size, callbacks=[cnn_model_checkpoint, early_stop, lr_reduction])\n",
    "        self.model.load_weights(f'fine_tuned_cnn_model_weights_using_mel_spectrogram_{n_mels}.h5')\n",
    "        return history\n",
    "    \n",
    "    def balanced_resampling(self, X, y):\n",
    "        \"\"\"\n",
    "        Xử lý lệch dữ liệu bằng cách kết hợp xóa ngẫu nhiên các mẫu từ các lớp dư thừa và thêm ngẫu nhiên các mẫu cho các lớp thiếu hụt.\n",
    "        \"\"\"\n",
    "        # Đếm số lượng mẫu cho mỗi lớp\n",
    "        counter = Counter(np.argmax(y, axis=1))\n",
    "        logger.info(f\"Original class distribution: {counter}\")\n",
    "\n",
    "        # Tìm lớp có ít mẫu nhất và lớp có nhiều mẫu nhất\n",
    "        min_samples = min(counter.values())\n",
    "        max_samples = max(counter.values())\n",
    "\n",
    "        # Khởi tạo danh sách lưu trữ các chỉ số của các mẫu được giữ lại\n",
    "        indices_to_keep = []\n",
    "        indices_to_add = []\n",
    "\n",
    "        for label in counter.keys():\n",
    "            # Lấy tất cả các chỉ số của các mẫu thuộc lớp này\n",
    "            class_indices = np.where(np.argmax(y, axis=1) == label)[0]\n",
    "            \n",
    "            # Xóa ngẫu nhiên nếu số lượng mẫu lớn hơn min_samples\n",
    "            if len(class_indices) > min_samples:\n",
    "                np.random.shuffle(class_indices)\n",
    "                indices_to_keep.extend(class_indices[:min_samples])\n",
    "            # Thêm ngẫu nhiên nếu số lượng mẫu nhỏ hơn max_samples\n",
    "            elif len(class_indices) < max_samples:\n",
    "                indices_to_keep.extend(class_indices)\n",
    "                indices_to_add.extend(resample(class_indices, replace=True, n_samples=max_samples - len(class_indices), random_state=42))\n",
    "\n",
    "        # Lấy các mẫu được giữ lại từ X và y\n",
    "        indices_to_keep.extend(indices_to_add)\n",
    "        X_balanced = X[indices_to_keep]\n",
    "        y_balanced = y[indices_to_keep]\n",
    "\n",
    "        # Đếm lại số lượng mẫu cho mỗi lớp sau khi cân bằng\n",
    "        counter_balanced = Counter(np.argmax(y_balanced, axis=1))\n",
    "        logger.info(f\"Balanced class distribution: {counter_balanced}\")\n",
    "\n",
    "        return X_balanced, y_balanced\n",
    "\n",
    "    def plot_confusion_matrix(self, X_test, y_test, labels):\n",
    "        \"\"\"\n",
    "        Vẽ ma trận nhầm lẫn cho bộ dữ liệu kiểm tra.\n",
    "        \"\"\"\n",
    "        # Dự đoán nhãn cho bộ dữ liệu kiểm tra\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "        # Tính toán ma trận nhầm lẫn\n",
    "        cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "        # Vẽ ma trận nhầm lẫn sử dụng seaborn\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_training_history(self, history):\n",
    "        \"\"\"\n",
    "        Vẽ biểu đồ lịch sử huấn luyện (accuracy và loss).\n",
    "        \"\"\"\n",
    "        # Plot training & validation accuracy values\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('Model accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "        # Plot training & validation loss values\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('Model loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
